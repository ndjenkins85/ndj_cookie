{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60070c6",
   "metadata": {},
   "source": [
    "# Basic statistics\n",
    "\n",
    "This notebook is a collation of basic stats study materials from a few sources.\n",
    "The aim is to create a single notebook where I can record my learnings and quickly look up concepts.\n",
    "\n",
    "Sources:\n",
    "- [A Cartoon Guide to statistics](https://www.amazon.es/Cartoon-Guide-Statistics/dp/0062731025)\n",
    "- [Hackerrank - 10 days of statistics](https://www.hackerrank.com/domains/tutorials/10-days-of-statistics)\n",
    "- [Rice University - Online Statistics Education](https://onlinestatbook.com/2/index.html)\n",
    "- [Ace the Data Science Interview](https://www.amazon.com/Ace-Data-Science-Interview-Questions/dp/0578973839)\n",
    "- [Machine learning mastery](https://machinelearningmastery.com)\n",
    "\n",
    "Contents:\n",
    "- Data description\n",
    "- Probability\n",
    "- Random variables\n",
    "- Distributions\n",
    "- Sampling\n",
    "- Confidence intervals\n",
    "- Hypothesis testing\n",
    "- Comparing two populations\n",
    "- Regression\n",
    "- Correlations\n",
    "\n",
    "Not covered in above (so far)\n",
    "- Bayes likelihood\n",
    "- Confusion matrix / ROC / AUC\n",
    "- Multiple testing correction (product book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use latest code in directory. Alternatively, run poetry install so the package is used instead.\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# from ndj_pipeline import db, model, transform, utils\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\", \n",
    "    handlers=[logging.StreamHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957567d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(\"data\", \"processed\", \"titanic.parquet\")\n",
    "logging.info(f\"Loading data from {input_path}\")\n",
    "data = pd.read_parquet(input_path)\n",
    "\n",
    "data = data.dropna(subset=['age', 'sex'])\n",
    "data['name_u'] = data['name'].str.contains('u').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc9715",
   "metadata": {},
   "source": [
    "# Data description\n",
    "\n",
    "- Summary statistics\n",
    "    - x1, x2, x3, xn\n",
    "    - Mean x̄\n",
    "    - Σ summation\n",
    "    - Median\n",
    "    - Interquartile range\n",
    "- Variability and Standard deviation (s)\n",
    "- Z scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09766d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean, median, mode\n",
    "# https://www.hackerrank.com/challenges/s10-basic-statistics/problem?isFullScreen=true\n",
    "x_raw = \"64630 11735 14216 99233 14470 4978 73429 38120 51135 67060\"\n",
    "\n",
    "x = [int(x) for x in x_raw.split(\" \")]\n",
    "x = sorted(x)\n",
    "\n",
    "# Mean\n",
    "mean = sum(x) / len(x)\n",
    "\n",
    "# Mode\n",
    "if len(x) % 2 == 0:\n",
    "    half = int(len(x) / 2)\n",
    "    median = x[half-1:half+1]\n",
    "    median = sum(median) / 2\n",
    "else:\n",
    "    half = int(len(x) / 2)\n",
    "    median = x[half]\n",
    "    \n",
    "# Mode\n",
    "counts = defaultdict(int)\n",
    "for num in x:\n",
    "    counts[num] += 1\n",
    "    \n",
    "max_count = max(counts.values())\n",
    "mode = min([num for num, count in counts.items() if count==max_count])\n",
    "\n",
    "print(f\"{mean:.1f}\")\n",
    "print(f\"{median:.1f}\")\n",
    "print(f\"{mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fede6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted mean\n",
    "def weightedMean(X, W):\n",
    "    sum_product = 0\n",
    "    for i in range(len(W)):\n",
    "        sum_product += X[i] * W[i]\n",
    "\n",
    "    answer = sum_product / sum(W)\n",
    "    print(f\"{answer:.1f}\")\n",
    "    \n",
    "    \n",
    "# n = int(input().strip())\n",
    "# vals = list(map(int, input().rstrip().split()))\n",
    "# weights = list(map(int, input().rstrip().split()))\n",
    "# weightedMean(vals, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc990d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartiles and interquartile range\n",
    "def quartiles(arr):\n",
    "    arr = sorted(arr)\n",
    "\n",
    "    mid = get_lower_mid_index(arr)    \n",
    "    q2 = get_median(arr)\n",
    "\n",
    "    if len(arr) % 2:\n",
    "        q1 = arr[:mid]\n",
    "        q3 = arr[mid + 1:]\n",
    "    else:\n",
    "        q1 = arr[:mid + 1]\n",
    "        q3 = arr[mid + 1:]\n",
    "        \n",
    "    q1 = get_median(q1)\n",
    "    q3 = get_median(q3)\n",
    "        \n",
    "    return [q1, q2, q3]\n",
    "\n",
    "\n",
    "def get_median(arr):\n",
    "    mid = get_lower_mid_index(arr)\n",
    "    if len(arr) % 2:\n",
    "        median = arr[mid]\n",
    "    else:\n",
    "        median = sum(arr[mid:mid + 2]) / 2\n",
    "    return median\n",
    "\n",
    "\n",
    "def get_lower_mid_index(arr):\n",
    "    return int((len(arr) - 1) / 2)\n",
    "\n",
    "    \n",
    "def interQuartile(values, freqs):\n",
    "    all_values = get_all_values(values, freqs)\n",
    "    q1, q2, q3 = quartiles(all_values)\n",
    "    print(round(float(q3) - float(q1), 1))\n",
    "    \n",
    "\n",
    "def get_all_values(values, freqs):\n",
    "    all_values = []\n",
    "    for i in range(len(freqs)):\n",
    "        for f in range(freqs[i]):\n",
    "            all_values.append(values[i])\n",
    "    return all_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6539a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = \"64630 11735 14216 99233 14470 4978 73429 38120 51135 67060\"\n",
    "x = [int(x) for x in x_raw.split(\" \")]\n",
    "quartiles(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3797844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variation and standard deviation\n",
    "def stdDev(X):    \n",
    "    mean = sum(X) / len(X)\n",
    "\n",
    "    variance = sum([(mean - x)**2 for x in X]) / len(X)\n",
    "    std = variance**0.5\n",
    "    print(f\"{std:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "stdDev(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fd781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0fbdc9",
   "metadata": {},
   "source": [
    "# Probability\n",
    "\n",
    "- Basic definitions\n",
    "    - Random experiment\n",
    "    - Elementary outcomes\n",
    "    - Sample space\n",
    "    - P(Oi) >= 0\n",
    "    - P(O1) + P(O2) + P(On) = 1\n",
    "- Event, event elementary outcomes, probability\n",
    "- Addition rule\n",
    "    - P(E OR F) = P(E) + P(F) - P(E AND F)\n",
    "    - P(E OR F) = P(E) + P(F)  (mutually exclusive only)\n",
    "- Subtraction rule\n",
    "    - P(E) = 1 - P(NOT E)\n",
    "    - Very useful for ‘chance no 12’s are thrown’ problems\n",
    "- Conditional probability\n",
    "    - P(E | F) = P(E and F) / P(F)\n",
    "- Multiplication rule\n",
    "    - P(E and F) = P(E | F) * P(F)\n",
    "    - P(E AND F) = P(E) * P(F) (if independent)\n",
    "- Disease example\n",
    "    - Setup\n",
    "        - 1 / 1000 infected\n",
    "        - Positive 99% of the time for those with disease\n",
    "        - 2% of uninfected patients also test positive\n",
    "        - You tested positive, what is your chance of having disease?\n",
    "    - Chance of having disease goes to 0.0472 if positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the chance I receive at least one offer from a company?\n",
    "# Chance of an offer\n",
    "google = 0.05\n",
    "facebook = 0.6\n",
    "lyft = 0.333\n",
    "\n",
    "1 - ((1 - google) * (1 - facebook) * (1 - lyft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the probability that I get an offer from all companies?\n",
    "google * facebook * lyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two people throw a biased coin with 60% of heads\n",
    "# Conditional probability: Whats the probability of both heads coming up? \n",
    "# What about after knowing 'someone' has heads?\n",
    "print(0.36 / (0.24 + 0.24 + 0.36))\n",
    "\n",
    "pd.DataFrame([[0.4*0.4, 0.6*0.4], [0.4*0.6, 0.6*0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57704d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example disease problem\n",
    "# Rare disease affects 1 in 1000 people\n",
    "# If person has disease, test comes back positive 99% of time\n",
    "# If person does not have disease, test comes back positive 2% of time\n",
    "# What are chances of having the disease if you test positive?\n",
    "\n",
    "\n",
    "print(99 / (99+1998))\n",
    "pd.DataFrame([[97902, 1], [1998, 99]])\n",
    "\n",
    "# Method: Get a large number of people as the table total, i.e. 100k\n",
    "# Fill in the disease column, then 2% false positive, then leftover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birthday problem, given n people, what are odds at least two people share a birthday?\n",
    "n = 23\n",
    "\n",
    "prob = 1\n",
    "for i in range(n):\n",
    "    available_days = 365 - i\n",
    "    prob *= available_days / 365\n",
    "    \n",
    "1 - prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4002b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monty hall\n",
    "# Three doors, there is a car behind one, you pick door A.\n",
    "# Monty removes a door which does not have a car i.e. door C.\n",
    "# Should you stay or switch? What are the odds?\n",
    "doors = 3\n",
    "remove = 1\n",
    "\n",
    "options = doors - remove - 1\n",
    "\n",
    "correct_first_time = 1 / doors\n",
    "correct_after_switch = (1 - correct_first_time) / options\n",
    "\n",
    "print(correct_first_time, correct_after_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b16c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f2cf1ee",
   "metadata": {},
   "source": [
    "# Random variables\n",
    "\n",
    "- Random variable \n",
    "    - X\n",
    "    - Numerical outcome of a random experiment\n",
    "    - Features of a data point\n",
    "    - x is a single value of X, i.e. category levels\n",
    "- Probability distributions (model or population properties)\n",
    "    - Mean of X - μ\n",
    "    - Variance of X - σ\n",
    "- Expected value\n",
    "    - E[X]\n",
    "    - μ = Σ x * p(x)\n",
    "- Expected variance\n",
    "    - σ² = Σ(x - μ)² * p(x)\n",
    "- Continuous random variables\n",
    "    - A specific point has probability = 0 (continuous)\n",
    "    - Probability density function (+ cumulative)\n",
    "    - μ =∫ x* f(x)dx\n",
    "    - σ² = ∫ (x - μ)² * f(x)dx\n",
    "- Adding random variables\n",
    "    - E[aX +b] = a * E[X] + b\n",
    "    - σ²(aX + b) = a²σ²(X)\n",
    "    - Many random variables\n",
    "        - Expected: Σ E[Xi]\n",
    "        - Variance: Σσ²(Xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b2f31",
   "metadata": {},
   "source": [
    "A large elevator can transport a maximum of  pounds. Suppose a load of cargo containing  boxes must be transported via the elevator. The box weight of this type of cargo follows a distribution with a mean of  pounds and a standard deviation of  pounds. Based on this information, what is the probability that all  boxes can be safely loaded into the freight elevator and transported?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight = 9800\n",
    "number_boxes = 49\n",
    "box_mean = 205\n",
    "box_sd = 15\n",
    "\n",
    "total_mean = number_boxes * box_mean\n",
    "total_sd = box_sd * number_boxes ** 0.5\n",
    "\n",
    "# Probability all can be loaded into elevator\n",
    "stats.norm.cdf(max_weight, total_mean, total_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39815b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d575301d",
   "metadata": {},
   "source": [
    "# A tale of two distributions\n",
    "\n",
    "- Bernoulli trials\n",
    "- Binomial random variable\n",
    "    - x successes in n repeated trials with p success probability\n",
    "    - (n choose k) * p ** k * (1 - p) ** (n - k)\n",
    "    - f = math.factorial\n",
    "    - f(a) / (f(b) * f(a - b))\n",
    "    - Pascal’s triangle\n",
    "    - μ = np\n",
    "    - σ² = np(1-p)\n",
    "- Poisson distribution\n",
    "    - p = ((math.e ** -u) * (u ** x)) / x!\n",
    "- Standard normal distribution\n",
    "    - (1 / (2 * pi)**0.5) * e ^ - (z² / 2)\n",
    "    - μ = 0\n",
    "    - σ = 1\n",
    "    - z = x - μ / σ\n",
    "- Fuzzy central limit theorem\n",
    "    - Data that are influenced by many small and unrelated random effects are approximately normally distributed\n",
    "    - SN distribution approximates binomial random variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e99943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinations can be used to form Pascal's triangle\n",
    "for i in range(10+1):\n",
    "    print(math.comb(10,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50620a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many failures over x bernulli trials?\n",
    "# Nail factory gives us 10 samples, nails are usually good (88% of time).\n",
    "p_ok = 0.88\n",
    "p_fail = 1 - p_ok\n",
    "\n",
    "# Will sum to 1\n",
    "(  (p_ok ** 10 * p_fail**0) * 1 # no failures\n",
    " + (p_ok ** 9 * p_fail**1) * 10 # one failure\n",
    " + (p_ok ** 8 * p_fail**2) * 45 # two failures\n",
    "#  + (p_ok ** 7 * p_fail**3) * 120\n",
    "#  + (p_ok ** 6 * p_fail**4) * 210\n",
    "#  + (p_ok ** 5 * p_fail**5) * 252\n",
    "#  + (p_ok ** 4 * p_fail**6) * 210\n",
    "#  + (p_ok ** 3 * p_fail**7) * 120\n",
    "#  + (p_ok ** 2 * p_fail**8) * 45 \n",
    "#  + (p_ok ** 1 * p_fail**9) * 10\n",
    "#  + (p_ok ** 0 * p_fail**10) * 1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ec82c",
   "metadata": {},
   "source": [
    "Acme Realty company sells an average of 2 homes per day. What is the probability that exactly 3 homes will be sold tomorrow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4142227",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = 2\n",
    "k = 3\n",
    "\n",
    "(lm**k * math.e**(-lm))  / math.factorial(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec6543",
   "metadata": {},
   "source": [
    "Suppose the average number of lions seen by tourists on a one-day safari is 5. What is the probability that tourists will see fewer than 3 lions on the next one-day safari?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = 5\n",
    "k = 3\n",
    "\n",
    "(\n",
    "(lm**0 * math.e**(-lm))  / math.factorial(0)\n",
    "+ (lm**1 * math.e**(-lm))  / math.factorial(1)\n",
    "+ (lm**2 * math.e**(-lm))  / math.factorial(2)\n",
    "+ (lm**3 * math.e**(-lm))  / math.factorial(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c00ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DnD chance of getting 2x 20's\n",
    "f = math.factorial\n",
    "\n",
    "# success is odds of getting an 18 with 4 dice drop 1\n",
    "# on a single trial\n",
    "s = 6*4 / 6**4\n",
    "n = 6\n",
    "k = 2\n",
    "\n",
    "# over 6 rolls, what are chances of getting 2?\n",
    "n_choose_k = int(f(n) / (f(k) * f(n - k)))\n",
    "prob = (n_choose_k) * s**k * (1 - s)**(n - k)\n",
    "prob = round(prob, 5)\n",
    "\n",
    "print(f\"success: {round(s*100, 2)}%, ways: {n_choose_k} of {f(n)}, prob: {round(prob*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of getting at least one six in four rolls\n",
    "1 - (5 / 6)**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba683fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of getting one double six in 24 rolls\n",
    "1 - (35 / 36) ** 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34643ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4adcaf01",
   "metadata": {},
   "source": [
    "### Normal distribution\n",
    "![normal_distribution](http://mathbitsnotebook.com/Algebra2/Statistics/normalstandard.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ffe58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e34e2a2c",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "- Everything governed by 1 / n ** 0.5\n",
    "- Sample size and standard error\n",
    "    - Don’t know population p, can estimate p̂ from sample\n",
    "    - p̂ = x / n\n",
    "    - p̂ can be considered a random variable (Capital p̂)\n",
    "    - SD: o(Capital p̂) = (p * (1 - p)) ** 0.5 / n ** 0.5\n",
    "    - Thus spread governed by 1 / n ** 0.5\n",
    "- Sampling error\n",
    "    - From above, SD of P hat\n",
    "    - Increasing sample size by 4 reduces spread by 2\n",
    "- Sampling distribution of the mean\n",
    "    - Sample mean x̄ = (x1 + x2 + xn) / n\n",
    "    - E[x̄] = μ\n",
    "    - σ(x̄) = σ / n ** 0.5 \n",
    "    - Variances of Xi/n add to give variance of x̄\n",
    "- Central limit theorem\n",
    "    - Random samples of size n\n",
    "    - As n gets large, x̄ approaches normal distribution\n",
    "    - With mean μ and SD σ / n ** 0.5\n",
    "- Student’s t-distribution\n",
    "    - CLT depends on large sample size and need known SD\n",
    "    - Use unbiased standard deviation of the sample\n",
    "    - 1 / (n - 1) Σ (xi - x̄)² \n",
    "    - Introduces more uncertainty through 1-n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b249ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDF\n",
    "# norm.cdf: cumulative distribution function is sample, mean, SD. \n",
    "# Or use it with the Z score\n",
    "\n",
    "x = stats.norm.cdf(19.5, 20, 2)\n",
    "logging.info(f\"-0.25 SD cumulative: {x:.3f}\")\n",
    "\n",
    "x = stats.norm.cdf(-0.25)\n",
    "logging.info(f\"Same same: {x:.3f}\")\n",
    "\n",
    "x = stats.norm.cdf(22, 20, 2) - stats.norm.cdf(20, 20, 2)\n",
    "logging.info(f\"1 SD difference: {x:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80bf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7d4d1a3",
   "metadata": {},
   "source": [
    "# Confidence intervals\n",
    "\n",
    "- Opposite of the above, given a sample what can infer for pop\n",
    "- Proportion confidence intervals (standard error)\n",
    "    - SE(p̂) = (p̂ * (1 - p̂)) ** 0.5 / n ** 0.5\n",
    "- How much sample n given confidence and acceptable error\n",
    "    - estimated_n = (z_score ** 2 * p * (1 - p)) / acceptable_error ** 2\n",
    "- Means confidence intervals (standard error)\n",
    "    - sample_error = ssd / n ** 0.5\n",
    "    - 95% confidence is sample_error * z score (1.96)\n",
    "- Student’s T\n",
    "    - Useful for smaller samples i.e. less than 50\n",
    "- All standard errors are proportional to 1 / n ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polling example; How much sample is required to have small error with high confidence?\n",
    "confidence = 0.99\n",
    "error = 0.01\n",
    "p = 0.5 # a guess\n",
    "\n",
    "# One tailed\n",
    "z = stats.norm.ppf(confidence + (1 - confidence) / 2)\n",
    "\n",
    "n = (z**2 * (p * (1-p))) / (\n",
    "error ** 2\n",
    ")\n",
    "print(f\"z score: {z:.3f}, sample needed: {n:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f41ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence interval for a proportion\n",
    "p̂ = 0.55\n",
    "n = 1000\n",
    "SD_p̂ = (p̂ * (1 - p̂)) **0.5 / n **0.5\n",
    "SD_p̂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f813373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus, with 95% confidence (z score), population probability is within 0.55 +- 0.031\n",
    "# Can use different confidence levels using different z scores\n",
    "SD_p̂ * -1.96, SD_p̂ * 1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119616bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE; the above IS VERY SIMILAR to 1/sqrt(n)\n",
    "1 / (1000**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The closer p̂ is to 50%, the more uncertainty, closer to 1 or 0, less uncertainty\n",
    "p̂ = 0.9\n",
    "n = 1000\n",
    "SD_p̂ = (p̂ * (1 - p̂)) **0.5 / n **0.5\n",
    "SD_p̂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The higher n, the less uncertainty; remember 4x n is about 2x less uncertainty\n",
    "p̂ = 0.5\n",
    "n = 4000\n",
    "SD_p̂ = (p̂ * (1 - p̂)) **0.5 / n **0.5\n",
    "SD_p̂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want 99% confidence with an error +- 0.01, what n?\n",
    "z = 2.58\n",
    "p = 0.5\n",
    "e = 0.01\n",
    "\n",
    "n = (z**2 * p * (1 - p)) / e**2\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample \n",
    "# 92 students\n",
    "ssd = 23.7\n",
    "n = 92\n",
    "mean = 145.2\n",
    "\n",
    "sample_error = ssd / n**0.5\n",
    "sample_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample error * z value\n",
    "mean, sample_error * 1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383d8e5",
   "metadata": {},
   "source": [
    "# Hypothesis testing\n",
    "\n",
    "- The null hypothesis\n",
    "    1. We are working with two samples of data and want to assess if they are statistically different\n",
    "    2. Null hypothesis states that they are the same, and any differences are due to chance\n",
    "    3. By selecting the right test to the type of data (proportion, mean) and assumptions, we can derive standardised scores such as chi squared score or T score which can be looked up to determine the probability value (p value)\n",
    "    4. The probability of observing the difference if the null hypothesis is true (or more extreme difference)\n",
    "    5. When p values less than 0.05 we usually reject, but we should be aware of multiple testing\n",
    "- Power analysis\n",
    "    - Definition\n",
    "        - Beta is the failure to reject a false null hypothesis\n",
    "        - Probability of missing an effect that is really there\n",
    "        - Power probability of detecting an effect that is really there\n",
    "        - Power = 1 - b\n",
    "        - By convention, we want 80% power\n",
    "    - Calculations\n",
    "        - Minimum practical effect\n",
    "            - From business, or former studies\n",
    "        - Standard deviation\n",
    "            - The control likely has been measured before\n",
    "        - One or two tailed test    \n",
    "    - Factors\n",
    "        - Sample size (more good)\n",
    "        - Variability (more bad)\n",
    "        - Difference between mean and hypothetical mean (more better)\n",
    "        - Significance level required (more bad)\n",
    "        - One tail vs two tailed (one better)\n",
    "    - Rough calculation\n",
    "        - n ~= (16 * σ ** 2) / d ** 2\n",
    "        - Where σ is SD, d is difference in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4bea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a14953d",
   "metadata": {},
   "source": [
    "# Comparing two populations\n",
    "\n",
    "- Comparing success rate (proportion) with z score\n",
    "- Comparing means of two populations \n",
    "    - With z score (large sample)\n",
    "    - With T score (small sample)\n",
    "        - Equal variance or unequal variance (more conservative)\n",
    "        - One tailed (hypothesis that it will be bigger/smaller) or two tailed (no hypothesis, more conservative)    \n",
    "- Paired comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42172d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T Tests\n",
    "# ttest_ind: T-test from two pandas Series input\n",
    "\n",
    "results = stats.ttest_ind(data.loc[data['survived']==1, 'fare'], data.loc[data['survived']==0, 'fare'])\n",
    "logging.info(\"Relationship between survival and fare paid\")\n",
    "logging.info(f\"T-test t-stat: {results.statistic:.3f}, p-value: {results.pvalue:.3f}. (expected difference)\")\n",
    "\n",
    "logging.info(\"\")\n",
    "\n",
    "results = stats.ttest_ind(data.loc[data['name_u']==1, 'age'], data.loc[data['name_u']==0, 'age'])\n",
    "logging.info(\"Relationship between letter 'u' in name and age\")\n",
    "logging.info(f\"T-test t-stat: {results.statistic:.3f}, p-value: {results.pvalue:.3f}. (expected no difference)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi squared tests\n",
    "# chi2_contingency: Chi squared tests from crosstab input\n",
    "results = stats.chi2_contingency(pd.crosstab(data['survived'], data['sex']))\n",
    "logging.info(\"Relationship between survival and sex\")\n",
    "logging.info(f\"Chi-squared Chi-value: {results[0]:.3f}, p-value: {results[1]:.3f}. (expected difference)\")\n",
    "\n",
    "logging.info(\"\")\n",
    "\n",
    "results = stats.chi2_contingency(pd.crosstab(data['name_u'], data['sex']))\n",
    "logging.info(\"Relationship between letter 'u' in name and sex\")\n",
    "logging.info(f\"Chi-squared Chi-value: {results[0]:.3f}, p-value: {results[1]:.3f}. (expected no difference)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired tests\n",
    "# Rather than getting mean of group A and group B... \n",
    "# both groups receive treatment at different times\n",
    "# The difference between their experiences in A, B is C = A-B \n",
    "# C has it's own mean and SD and much more statistical power\n",
    "mean = -0.6\n",
    "sd = 0.61\n",
    "n = 10\n",
    "t_critical_value = 2.26\n",
    "\n",
    "population_mean_lower = mean - t_critical_value * (sd / n**0.5)\n",
    "population_mean_upper = mean + t_critical_value * (sd / n**0.5)\n",
    "print(f\"{population_mean_lower:.3f}, {population_mean_upper:.3f}\")\n",
    "\n",
    "# As confidence interval does not cross 0, this indicates significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4a188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5abe5a90",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "- Least squares regression\n",
    "- Statsmodel regression\n",
    "\n",
    "- Linear regression\n",
    "    - Key assumptions\n",
    "        - Linearity \n",
    "        - Independence of data\n",
    "        - Normally distributed data\n",
    "        - Homoscedacity - errors are evenly distributed\n",
    "    - Problems\n",
    "        - Heteroscedacity\n",
    "        - Normality Q-Q plots\n",
    "        - Outliers\n",
    "        - Multicollinearity\n",
    "        \n",
    "\n",
    "- Logistic regression\n",
    "  - Logistic Function\n",
    "    - Sigmoid function, from infinity to 0, 1 (y)\n",
    "    - Logit function, from 0, 1 to infinities (y)\n",
    "  - Maximum likelihood estimation - Used to estimate betas\n",
    "  - Log likelihood function\n",
    "  - Gradient decent to maximise likelihood\n",
    "  - Estimating B: start random, compute gradients and update betas, repeat until converge\n",
    "  - Complexity analysis O(MNI), Each datapoint, each feature, each iteration\n",
    "  - Mini-batch gradient decent (best for large data)\n",
    "  - Further resources\n",
    "    - Data Science Pro https://www.youtube.com/watch?v=gN79XvB7vTo&list=PLY1Fi4XflWSsLoOQr-Ee2R4qRFejtCFRh&index=2\n",
    "    - Brandon Foltz https://www.youtube.com/watch?v=NmjT1_nClzg\n",
    "- Regularisation, ridge regression vs lasso\n",
    "    - L1 lasso - absolute value of coefficients\n",
    "    - L2 ridge - squared value of coefficients\n",
    "    - Can combine for elastic net\n",
    "    - L1 can zero out coefficients, useful for feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a784a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares regression\n",
    "values = [(95, 85),\n",
    "        (85, 95),\n",
    "        (80, 70),\n",
    "        (70, 65),\n",
    "        (60, 70)]\n",
    "\n",
    "x = [z[0] for z in values]\n",
    "y = [z[1] for z in values]\n",
    "\n",
    "mean_x = sum(x) / len(x)\n",
    "mean_y = sum(y) / len(y)\n",
    "\n",
    "x_diff = [xn - mean_x for xn in x]\n",
    "y_diff = [yn - mean_y for yn in y]\n",
    "\n",
    "sd_x = (sum([xn**2 for xn in x_diff]) / len(x))**0.5\n",
    "sd_y = (sum([yn**2 for yn in y_diff]) / len(y))**0.5\n",
    "\n",
    "cov = 0\n",
    "for i in range(len(x_diff)):\n",
    "    cov += x_diff[i] * y_diff[i] \n",
    "\n",
    "correlation = cov / (len(x) * sd_x * sd_y)\n",
    "\n",
    "print(round(correlation, 3))\n",
    "\n",
    "b = correlation * (sd_y / sd_x)\n",
    "print(b)\n",
    "\n",
    "a = mean_y - b * mean_x\n",
    "print(a)\n",
    "\n",
    "round(a + b*80, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e296cf",
   "metadata": {},
   "source": [
    "statsmodels.api\n",
    "\n",
    "- Includes param p values unlike sklearn\n",
    "- API different; data -> model then fit, rather than sklearn model then data -> fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodel linear regression\n",
    "target = \"survived\"\n",
    "features = [\"pclass\", \"age\"]\n",
    "data_ready = data.dropna(subset=['age', \"pclass\", \"survived\"])\n",
    "\n",
    "data_ready[\"_constant\"] = 1\n",
    "features.append(\"_constant\")\n",
    "\n",
    "# Need to add constant either through data\n",
    "# Beware Int64 types\n",
    "# Predictions are through 'results' variable\n",
    "model = sm.OLS(data_ready[target], data_ready[features])\n",
    "results = model.fit()\n",
    "\n",
    "logging.info(results.pvalues)\n",
    "logging.info(results.params)\n",
    "logging.info(results.rsquared)\n",
    "\n",
    "results.predict(data_ready[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add full linear and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tatwan/Linear-Regression-Implementation-in-Python/blob/master/Linear_Regression_Python.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c804dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost_m(x, y, theta):\n",
    "    m = len(y)\n",
    "    h_x = np.dot(x, theta)\n",
    "    j = np.sum(np.square(h_x - y))/(2*m)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8efc11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d66ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_init = np.zeros((len(features), 1))\n",
    "computeCost_m(data_ready[features], data_ready[target], theta_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fa27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79394dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe120c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, Y, theta, alpha, num_iters):\n",
    "    m = len(Y)\n",
    "    p = np.copy(X)\n",
    "    t = np.copy(theta)\n",
    "    j = []\n",
    "    print('Running Gradient Descent')\n",
    "    for i in range(0,num_iters+1):\n",
    "        cost = computeCost_m(p, Y, t)\n",
    "        j.append(cost)\n",
    "        h_x = np.dot(p, t)\n",
    "        err = h_x - Y\n",
    "        for f in range(theta.size):\n",
    "            t[f] = t[f] - alpha/m *(np.sum((np.dot(p[:,f].T, err))))\n",
    "    return j, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a3b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta_init = np.zeros((3, 1))\n",
    "alpha = 0.01\n",
    "num_iters = 5000\n",
    "theta_init = np.zeros((19, 1))\n",
    "cost, theta_final = gradientDescentMulti(x_norm, Y, theta_init, alpha, num_iters)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(cost)\n",
    "plt.xlabel('No. of Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03baad2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "966ced24",
   "metadata": {},
   "source": [
    "# Correlations\n",
    "- Pearson correlation coefficient\n",
    "- Spearman rank correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d390214",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = \"10 9.8 8 7.8 7.7 1.7 6 5 1.4 2 \"\n",
    "y_raw = \"200 44 32 24 22 17 15 12 8 4\"\n",
    "\n",
    "x = [float(xn) for xn in x_raw.strip().split(\" \")]\n",
    "y = [float(yn) for yn in y_raw.strip().split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation coefficient\n",
    "mean_x = sum(x) / len(x)\n",
    "mean_y = sum(y) / len(y)\n",
    "\n",
    "x_diff = [xn - mean_x for xn in x]\n",
    "y_diff = [yn - mean_y for yn in y]\n",
    "\n",
    "sd_x = (sum([xn**2 for xn in x_diff]) / len(x))**0.5\n",
    "sd_y = (sum([yn**2 for yn in y_diff]) / len(y))**0.5\n",
    "\n",
    "cov = 0\n",
    "for i in range(len(x_diff)):\n",
    "    cov += x_diff[i] * y_diff[i] \n",
    "\n",
    "correlation = cov / (len(x) * sd_x * sd_y)\n",
    "\n",
    "print(round(correlation, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman rank coefficient\n",
    "x_rank = dict([(x_rank, i) for i, x_rank in enumerate(sorted(x))])\n",
    "y_rank = dict([(y_rank, i) for i, y_rank in enumerate(sorted(y))])\n",
    "\n",
    "x = [(xn, x_rank[xn]) for xn in x]\n",
    "y = [(yn, y_rank[yn]) for yn in y]\n",
    "\n",
    "d = 0\n",
    "for i in range(len(x)):\n",
    "    d += (x[i][1] - y[i][1])**2\n",
    "\n",
    "spearman = 1 - ((6 * d) / (len(x) * (len(x)**2 - 1)))    \n",
    "print(round(spearman, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe24270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da19b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe652ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5ac9668",
   "metadata": {},
   "source": [
    "# Time series analysis\n",
    "\n",
    "Linear approaches\n",
    "- ARIMA\n",
    "    - Efficient and interpretable\n",
    "    - Strong model assumptions, simple\n",
    "\n",
    "State-space models\n",
    "- Kalman filter, Hidden Markov model\n",
    "    - More flexible and interpretable\n",
    "    - Expensive inference\n",
    "\n",
    "Deep sequence models (DCRNN)\n",
    "- RNN, attention\n",
    "    - Efficient and non-linear\n",
    "    - Hard to interpret\n",
    "- DCRNN\n",
    "    - K-step diffusion\n",
    "    - Unit: DCGRU Diffusional convolutional gated recurrent unit\n",
    "        - input: sequence of history graphs\n",
    "        - outputs: sequence of future graphs\n",
    "\n",
    "Historical average (google) is a really good baseline\n",
    "ARIMA can/can’t be better, good in short term, not so good in longer time\n",
    "DCRNN best in short term and long term \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d1d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad735b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
